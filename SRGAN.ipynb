{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b261188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de chargement des images dans un dossier\n",
    "\"\"\"\n",
    "def load_dataset(path, image_shape):\n",
    "    \n",
    "    list_im = []\n",
    "    ims = []\n",
    "    \n",
    "    #On recupere la liste des fichiers contenu dans le dossier\n",
    "    for im in os.listdir(path):\n",
    "        list_im.append(os.path.join(path,im))\n",
    "    \n",
    "    #On charge les images, on les resize et on les transforme en numpy array\n",
    "    for i in list_im:\n",
    "        ims.append(np.array(Image.open(i).resize(image_shape)))\n",
    "    \n",
    "    #On retourne la liste d images de type numpy array\n",
    "    return np.array(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59bb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de normalisation des donnees : les pixels des images seront compris entre 0 et 1\n",
    "\"\"\"\n",
    "def normalisation(dataset):\n",
    "    return (dataset.astype(np.float32) - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86515bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de prediction de nouvelles images et affichage des résultats\n",
    "\"\"\"\n",
    "def prediction_et_resultat_plot(x_test_hr, x_test_lr, generateur, nb_images, it, mode):\n",
    "    \n",
    "    #On choisit aléatoirement nb_images parmi la base de test\n",
    "    indice_images = np.random.randint(0, x_test_hr.shape[0], nb_images)\n",
    "    lr_images = x_test_lr[indice_images]\n",
    "    hr_images = x_test_hr[indice_images]\n",
    "    \n",
    "    #Selon le mode, on charge les poids puis on prédit\n",
    "    if mode == \"train\":\n",
    "        images_generes = generator.predict(lr_images)\n",
    "    elif mode == \"inference\":\n",
    "        generateur.load_weights(\"./output2/gen_model_final.h5\")\n",
    "        images_generes = generateur.predict(lr_images)\n",
    "    \n",
    "    #Denormalisation des images\n",
    "    lr_images = 0.5 * lr_images + 0.5\n",
    "    hr_images = 0.5 * hr_images + 0.5\n",
    "    images_generes = 0.5 * images_generes + 0.5\n",
    "    \n",
    "    #Pour chaque, on cree un plot avec l image basse resolution / l image generee / l image haute resolution\n",
    "    for i in range(lr_images.shape[0]):\n",
    "        \n",
    "        plt.figure(figsize=(20, 40))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(lr_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image basse résolution\")\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(images_generes[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image générée\")\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(hr_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image haute résolution\")\n",
    "        \n",
    "        plt.savefig('./output2/result_image_%d.png' % i)\n",
    "        plt.close()  \n",
    "\n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55dd19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de chargement du modele VGG19\n",
    "\"\"\"\n",
    "def creation_vgg(hr_shape):\n",
    "    vgg = VGG19(include_top = False ,  input_shape = hr_shape , weights=\"imagenet\")\n",
    "    features = vgg.get_layer(index = 9).output\n",
    "    model = Model(inputs=[vgg.inputs], outputs=[features])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17f8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du discriminateur (architecture provenant de l'article de recherche du SRGAN(voir readme))\n",
    "\"\"\"\n",
    "def creation_discriminateur(hr_shape):\n",
    "\n",
    "    def discri_block(inp, filters, strides = 1, bn = True):\n",
    "        db = Conv2D(filters = filters, kernel_size = 3, strides = strides, padding='same')(inp)\n",
    "        if bn:\n",
    "            db = BatchNormalization(momentum = 0.8)(db)\n",
    "        db = LeakyReLU(alpha = 0.2)(db)\n",
    "        return db\n",
    "\n",
    "    inp = Input(shape = hr_shape)\n",
    "\n",
    "    d = discri_block(inp, 64, 1, bn=False)\n",
    "    d = discri_block(d, 64, 2, True)\n",
    "    d = discri_block(d, 128, 1, True)\n",
    "    d = discri_block(d, 128, 2, True)\n",
    "    d = discri_block(d, 256, 1, True)\n",
    "    d = discri_block(d, 256, 2, True)\n",
    "    d = discri_block(d, 512, 1, True)\n",
    "    d = discri_block(d, 512, 2, True)\n",
    "\n",
    "    d = Dense(1024)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    d_final = Dense(1, activation = 'sigmoid')(d)\n",
    "\n",
    "    return Model(inp, d_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb73397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du generateur (architecture provenant de l'article de recherche du SRGAN(voir readme))\n",
    "\"\"\"\n",
    "def creation_generateur(lr_shape):\n",
    "    \n",
    "    def residual_block(inp):\n",
    "    \n",
    "        model_rb = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(inp)\n",
    "        model_rb = BatchNormalization(momentum = 0.8)(model_rb)\n",
    "        model_rb = PReLU(alpha_initializer='zeros')(model_rb)\n",
    "        model_rb = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model_rb)\n",
    "        model_rb = BatchNormalization(momentum = 0.8)(model_rb)\n",
    "        model_rb = add([inp, model_rb])\n",
    "    \n",
    "        return model_rb\n",
    "\n",
    "    def deconvolution(inp):\n",
    "    \n",
    "        model_dc = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = \"same\")(inp)\n",
    "        model_dc = UpSampling2D(size = 2)(model_dc)\n",
    "        model_dc = LeakyReLU(alpha = 0.2)(model_dc)\n",
    "    \n",
    "        return model_dc\n",
    "\n",
    "    inp = Input(shape = lr_shape)\n",
    "\n",
    "    model_g = Conv2D(filters = 64, kernel_size=9, strides=1, padding='same')(inp)\n",
    "    model_g = PReLU(alpha_initializer='zeros')(model_g)\n",
    "    \n",
    "    sauv_out = model_g\n",
    "\n",
    "    for i in range(16):\n",
    "        model_g = residual_block(model_g)\n",
    "\n",
    "    model_g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='same')(model_g)\n",
    "    model_g = BatchNormalization(momentum=0.8)(model_g)\n",
    "    model_g = add([sauv_out, model_g])\n",
    "\n",
    "    for i in range(2):\n",
    "        model_g = deconvolution(model_g)\n",
    "\n",
    "    model_g = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = 'same', activation = 'tanh')(model_g)\n",
    "\n",
    "    return Model(inp, model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3767bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du SRGAN\n",
    "\"\"\"\n",
    "def creation_SRGAN(hr_shape, lr_shape):\n",
    "    \n",
    "    lr_images = Input(lr_shape)\n",
    "    hr_images = Input(hr_shape)\n",
    "    \n",
    "    generated_hr = generateur(lr_images)\n",
    "    generated_feature_map = vgg(generated_hr)\n",
    "    \n",
    "    #On entraine pas le discriminateur ici (on le fait avant)\n",
    "    discriminateur.trainable = False\n",
    "    \n",
    "    return Model([lr_images, hr_images], [discriminateur(generated_hr), generated_feature_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba5f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction d entrainement du modele\n",
    "\"\"\"\n",
    "def train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs, batch_size):\n",
    "        \n",
    "        shape_output_discrinateur = (16, 16, 1)\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(epochs + 1):\n",
    "\n",
    "            #On choisit aléatoirement nb_images parmi la base d entrainement\n",
    "            indice_images = np.random.randint(0, x_test_hr.shape[0], batch_size)\n",
    "            lr_images = x_test_lr[indice_images]\n",
    "            hr_images = x_test_hr[indice_images]\n",
    "\n",
    "            generated_images = generateur.predict(lr_images)\n",
    "            \n",
    "            #L output shape du discriminateur est : (batch_size,16,16,1)\n",
    "            #on associe la classe 1 aux vrais images et 0 aux images generees\n",
    "            target_1 = np.ones((batch_size,) + shape_output_discrinateur)\n",
    "            target_0 = np.zeros((batch_size,) + shape_output_discrinateur)\n",
    "            \n",
    "            #Entrainement du discriminateur et recuperation des erreurs\n",
    "            d_loss_vrai_im = discriminateur.train_on_batch(hr_images, target_1)\n",
    "            d_loss_gen_im = discriminateur.train_on_batch(generated_images, target_0)\n",
    "            \n",
    "            #Moyenne des erreurs\n",
    "            #d_loss = 0.5 * np.add(d_loss_vrai_im, d_loss_gen_im)\n",
    "\n",
    "            #On choisit aléatoirement nb_images parmi la base d entrainement\n",
    "            indice_images = np.random.randint(0, x_test_hr.shape[0], batch_size)\n",
    "            lr_images = x_test_lr[indice_images]\n",
    "            hr_images = x_test_hr[indice_images]\n",
    "\n",
    "            target_1 = np.ones((batch_size,) + shape_output_discrinateur)\n",
    "            \n",
    "            #On récupères les features maps des images huates résolutions (du modèle VGG19) \n",
    "            #pour les comparer aux features maps des images generees\n",
    "            \n",
    "            feature_map_hr_images = vgg.predict(hr_images)\n",
    "            \n",
    "            #Entrainement du SRGAN avec recuperation de l'erreur\n",
    "            g_loss = srgan.train_on_batch([lr_images, hr_images], [target_1, feature_map_hr_images])\n",
    "\n",
    "            #Suivi du temps d'apprentissage\n",
    "            time = datetime.datetime.now() - start_time\n",
    "            #Affichage des epochs et du temps\n",
    "            print(\"epoch : %d -- time :  %s\" % (epoch, time))\n",
    "                     \n",
    "            #Affichage des erreurs\n",
    "            #print(\"Loss HR , Loss LR, Loss GAN\")\n",
    "            #print(d_loss, g_loss)\n",
    "            \n",
    "            #Affichage des images generees et sauvegarde des poids des neurones des differents reseaux toutes les 1k images\n",
    "            if (epoch % 1000 == 0) and (epoch > 0):\n",
    "                prediction_et_resultat_plot(x_test_hr, x_test_lr, generator, 2, epoch, \"train\")\n",
    "                generateur.save_weights('./output2/gen_model_%d.h5' % epoch)\n",
    "                #discriminator.save_weights('./output2/dis_model_%d.h5' % epoch)\n",
    "                #combined.save_weights('./output2/srgan_model_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c6104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image haute resolution (hr) de taille 256*256\n",
    "#image basse resolution (lr) de taille 64*64\n",
    "#Facteur de 4 entre les images haute et basse résolution\n",
    "image_shape1 = (256,256)\n",
    "image_shape2 = (64,64)\n",
    "\n",
    "#Chargement / Resize / Normalisation des donnees\n",
    "x_train_hr = normalisation(load_dataset(\"./div2k/DIV2K_train_HR\", image_shape1))\n",
    "x_train_lr = normalisation(load_dataset(\"./div2k/DIV2K_train_LR_bicubic/X2\", image_shape2))\n",
    "x_test_hr = normalisation(load_dataset(\"./div2k/DIV2K_valid_HR\", image_shape1))\n",
    "x_test_lr = normalisation(load_dataset(\"./div2k/DIV2K_valid_LR_bicubic/X2\", image_shape2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a74679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\"\n",
    "#mode = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9072321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 -- time :  0:00:25.414697\n",
      "epoch : 1 -- time :  0:00:28.523527\n",
      "epoch : 2 -- time :  0:00:31.654955\n",
      "epoch : 3 -- time :  0:00:34.826622\n",
      "epoch : 4 -- time :  0:00:37.967155\n",
      "epoch : 5 -- time :  0:00:41.139949\n",
      "epoch : 6 -- time :  0:00:44.268165\n",
      "epoch : 7 -- time :  0:00:47.411929\n",
      "epoch : 8 -- time :  0:00:50.546468\n",
      "epoch : 9 -- time :  0:00:53.631740\n",
      "epoch : 10 -- time :  0:00:56.775452\n",
      "epoch : 11 -- time :  0:00:59.896094\n",
      "epoch : 12 -- time :  0:01:03.089120\n",
      "epoch : 13 -- time :  0:01:06.226826\n",
      "epoch : 14 -- time :  0:01:09.377295\n",
      "epoch : 15 -- time :  0:01:12.565969\n",
      "epoch : 16 -- time :  0:01:15.734150\n",
      "epoch : 17 -- time :  0:01:18.863649\n",
      "epoch : 18 -- time :  0:01:22.006377\n",
      "epoch : 19 -- time :  0:01:25.158026\n",
      "epoch : 20 -- time :  0:01:28.305491\n",
      "epoch : 21 -- time :  0:01:31.434977\n",
      "epoch : 22 -- time :  0:01:34.617291\n",
      "epoch : 23 -- time :  0:01:37.793029\n",
      "epoch : 24 -- time :  0:01:40.968794\n",
      "epoch : 25 -- time :  0:01:44.149196\n",
      "epoch : 26 -- time :  0:01:47.302553\n",
      "epoch : 27 -- time :  0:01:50.494227\n",
      "epoch : 28 -- time :  0:01:53.657056\n",
      "epoch : 29 -- time :  0:01:56.857275\n",
      "epoch : 30 -- time :  0:02:00.018547\n",
      "epoch : 31 -- time :  0:02:03.185907\n",
      "epoch : 32 -- time :  0:02:06.375870\n",
      "epoch : 33 -- time :  0:02:09.556939\n",
      "epoch : 34 -- time :  0:02:12.716382\n",
      "epoch : 35 -- time :  0:02:15.917345\n",
      "epoch : 36 -- time :  0:02:19.096043\n",
      "epoch : 37 -- time :  0:02:22.268982\n",
      "epoch : 38 -- time :  0:02:25.458456\n",
      "epoch : 39 -- time :  0:02:28.615009\n",
      "epoch : 40 -- time :  0:02:31.820259\n",
      "epoch : 41 -- time :  0:02:35.020361\n",
      "epoch : 42 -- time :  0:02:38.209345\n",
      "epoch : 43 -- time :  0:02:41.416874\n",
      "epoch : 44 -- time :  0:02:44.576384\n",
      "epoch : 45 -- time :  0:02:47.751919\n",
      "epoch : 46 -- time :  0:02:50.927268\n",
      "epoch : 47 -- time :  0:02:54.136793\n",
      "epoch : 48 -- time :  0:02:57.319533\n",
      "epoch : 49 -- time :  0:03:00.502101\n",
      "epoch : 50 -- time :  0:03:03.680865\n",
      "epoch : 51 -- time :  0:03:06.881401\n",
      "epoch : 52 -- time :  0:03:10.087843\n",
      "epoch : 53 -- time :  0:03:13.301619\n",
      "epoch : 54 -- time :  0:03:16.487922\n",
      "epoch : 55 -- time :  0:03:19.705308\n",
      "epoch : 56 -- time :  0:03:22.898921\n",
      "epoch : 57 -- time :  0:03:26.090477\n",
      "epoch : 58 -- time :  0:03:29.293597\n",
      "epoch : 59 -- time :  0:03:32.453702\n",
      "epoch : 60 -- time :  0:03:35.660098\n",
      "epoch : 61 -- time :  0:03:38.867557\n",
      "epoch : 62 -- time :  0:03:42.065835\n",
      "epoch : 63 -- time :  0:03:45.283123\n",
      "epoch : 64 -- time :  0:03:48.468234\n",
      "epoch : 65 -- time :  0:03:51.625965\n",
      "epoch : 66 -- time :  0:03:54.821500\n",
      "epoch : 67 -- time :  0:03:58.012830\n",
      "epoch : 68 -- time :  0:04:01.218866\n",
      "epoch : 69 -- time :  0:04:04.397335\n",
      "epoch : 70 -- time :  0:04:07.582941\n",
      "epoch : 71 -- time :  0:04:10.809259\n",
      "epoch : 72 -- time :  0:04:14.025799\n",
      "epoch : 73 -- time :  0:04:17.235812\n",
      "epoch : 74 -- time :  0:04:20.474349\n",
      "epoch : 75 -- time :  0:04:23.658311\n",
      "epoch : 76 -- time :  0:04:26.839394\n",
      "epoch : 77 -- time :  0:04:30.023527\n",
      "epoch : 78 -- time :  0:04:33.232390\n",
      "epoch : 79 -- time :  0:04:36.412226\n",
      "epoch : 80 -- time :  0:04:39.597260\n",
      "epoch : 81 -- time :  0:04:42.802811\n",
      "epoch : 82 -- time :  0:04:46.048896\n",
      "epoch : 83 -- time :  0:04:49.247501\n",
      "epoch : 84 -- time :  0:04:52.454552\n",
      "epoch : 85 -- time :  0:04:55.664446\n",
      "epoch : 86 -- time :  0:04:58.882214\n",
      "epoch : 87 -- time :  0:05:02.071118\n",
      "epoch : 88 -- time :  0:05:05.260321\n",
      "epoch : 89 -- time :  0:05:08.466719\n",
      "epoch : 90 -- time :  0:05:11.666690\n",
      "epoch : 91 -- time :  0:05:14.905271\n",
      "epoch : 92 -- time :  0:05:18.119173\n",
      "epoch : 93 -- time :  0:05:21.325345\n",
      "epoch : 94 -- time :  0:05:24.519194\n",
      "epoch : 95 -- time :  0:05:27.791441\n",
      "epoch : 96 -- time :  0:05:30.976115\n",
      "epoch : 97 -- time :  0:05:34.179040\n",
      "epoch : 98 -- time :  0:05:37.393113\n",
      "epoch : 99 -- time :  0:05:40.581929\n",
      "epoch : 100 -- time :  0:05:43.798849\n",
      "epoch : 101 -- time :  0:05:46.997006\n",
      "epoch : 102 -- time :  0:05:50.186436\n",
      "epoch : 103 -- time :  0:05:53.383120\n",
      "epoch : 104 -- time :  0:05:56.569147\n",
      "epoch : 105 -- time :  0:05:59.768419\n",
      "epoch : 106 -- time :  0:06:03.016779\n",
      "epoch : 107 -- time :  0:06:06.198824\n",
      "epoch : 108 -- time :  0:06:09.383875\n",
      "epoch : 109 -- time :  0:06:12.586197\n",
      "epoch : 110 -- time :  0:06:15.770513\n",
      "epoch : 111 -- time :  0:06:19.601597\n",
      "epoch : 112 -- time :  0:06:22.842642\n",
      "epoch : 113 -- time :  0:06:26.061929\n",
      "epoch : 114 -- time :  0:06:29.241728\n",
      "epoch : 115 -- time :  0:06:32.422144\n",
      "epoch : 116 -- time :  0:06:35.601835\n",
      "epoch : 117 -- time :  0:06:38.800941\n",
      "epoch : 118 -- time :  0:06:42.018635\n",
      "epoch : 119 -- time :  0:06:45.226798\n",
      "epoch : 120 -- time :  0:06:48.432121\n",
      "epoch : 121 -- time :  0:06:51.614545\n",
      "epoch : 122 -- time :  0:06:54.800364\n",
      "epoch : 123 -- time :  0:06:58.002106\n",
      "epoch : 124 -- time :  0:07:01.211032\n",
      "epoch : 125 -- time :  0:07:04.398617\n",
      "epoch : 126 -- time :  0:07:07.578264\n",
      "epoch : 127 -- time :  0:07:10.778429\n",
      "epoch : 128 -- time :  0:07:13.970088\n",
      "epoch : 129 -- time :  0:07:17.152398\n",
      "epoch : 130 -- time :  0:07:20.351578\n",
      "epoch : 131 -- time :  0:07:23.562740\n",
      "epoch : 132 -- time :  0:07:26.773990\n",
      "epoch : 133 -- time :  0:07:29.988072\n",
      "epoch : 134 -- time :  0:07:33.168169\n",
      "epoch : 135 -- time :  0:07:36.350018\n",
      "epoch : 136 -- time :  0:07:39.531412\n",
      "epoch : 137 -- time :  0:07:42.679067\n",
      "epoch : 138 -- time :  0:07:45.864764\n",
      "epoch : 139 -- time :  0:07:49.047713\n",
      "epoch : 140 -- time :  0:07:52.274032\n",
      "epoch : 141 -- time :  0:07:55.486063\n",
      "epoch : 142 -- time :  0:07:58.662941\n",
      "epoch : 143 -- time :  0:08:01.846062\n",
      "epoch : 144 -- time :  0:08:05.060471\n",
      "epoch : 145 -- time :  0:08:08.247281\n",
      "epoch : 146 -- time :  0:08:11.446120\n",
      "epoch : 147 -- time :  0:08:14.655941\n",
      "epoch : 148 -- time :  0:08:17.863550\n",
      "epoch : 149 -- time :  0:08:21.085299\n",
      "epoch : 150 -- time :  0:08:24.270147\n",
      "epoch : 151 -- time :  0:08:27.409511\n",
      "epoch : 152 -- time :  0:08:30.616945\n",
      "epoch : 153 -- time :  0:08:33.800066\n",
      "epoch : 154 -- time :  0:08:37.006150\n",
      "epoch : 155 -- time :  0:08:40.191890\n",
      "epoch : 156 -- time :  0:08:43.387033\n",
      "epoch : 157 -- time :  0:08:46.572579\n",
      "epoch : 158 -- time :  0:08:49.813301\n",
      "epoch : 159 -- time :  0:08:53.006257\n",
      "epoch : 160 -- time :  0:08:56.177691\n",
      "epoch : 161 -- time :  0:08:59.362772\n",
      "epoch : 162 -- time :  0:09:02.541628\n",
      "epoch : 163 -- time :  0:09:05.745222\n",
      "epoch : 164 -- time :  0:09:08.926090\n",
      "epoch : 165 -- time :  0:09:12.127677\n",
      "epoch : 166 -- time :  0:09:15.316695\n",
      "epoch : 167 -- time :  0:09:18.526038\n",
      "epoch : 168 -- time :  0:09:21.717191\n",
      "epoch : 169 -- time :  0:09:24.896436\n",
      "epoch : 170 -- time :  0:09:28.072462\n",
      "epoch : 171 -- time :  0:09:31.246966\n",
      "epoch : 172 -- time :  0:09:34.431414\n",
      "epoch : 173 -- time :  0:09:37.634324\n",
      "epoch : 174 -- time :  0:09:40.844139\n",
      "epoch : 175 -- time :  0:09:44.031348\n",
      "epoch : 176 -- time :  0:09:47.216567\n",
      "epoch : 177 -- time :  0:09:50.428150\n",
      "epoch : 178 -- time :  0:09:53.657616\n",
      "epoch : 179 -- time :  0:09:56.860729\n",
      "epoch : 180 -- time :  0:10:00.021974\n",
      "epoch : 181 -- time :  0:10:03.223426\n",
      "epoch : 182 -- time :  0:10:06.381985\n",
      "epoch : 183 -- time :  0:10:09.558175\n",
      "epoch : 184 -- time :  0:10:12.737076\n",
      "epoch : 185 -- time :  0:10:15.944480\n",
      "epoch : 186 -- time :  0:10:19.163193\n",
      "epoch : 187 -- time :  0:10:22.368455\n",
      "epoch : 188 -- time :  0:10:25.570917\n",
      "epoch : 189 -- time :  0:10:28.754267\n",
      "epoch : 190 -- time :  0:10:31.954662\n",
      "epoch : 191 -- time :  0:10:35.203484\n",
      "epoch : 192 -- time :  0:10:38.393137\n",
      "epoch : 193 -- time :  0:10:41.575296\n",
      "epoch : 194 -- time :  0:10:44.755415\n",
      "epoch : 195 -- time :  0:10:47.954455\n",
      "epoch : 196 -- time :  0:10:51.165431\n",
      "epoch : 197 -- time :  0:10:54.407362\n",
      "epoch : 198 -- time :  0:10:57.612506\n",
      "epoch : 199 -- time :  0:11:00.793619\n",
      "epoch : 200 -- time :  0:11:03.939919\n",
      "epoch : 201 -- time :  0:11:07.129098\n",
      "epoch : 202 -- time :  0:11:10.298147\n",
      "epoch : 203 -- time :  0:11:13.458421\n",
      "epoch : 204 -- time :  0:11:16.617338\n",
      "epoch : 205 -- time :  0:11:19.788664\n",
      "epoch : 206 -- time :  0:11:22.939724\n",
      "epoch : 207 -- time :  0:11:26.145086\n",
      "epoch : 208 -- time :  0:11:29.303940\n",
      "epoch : 209 -- time :  0:11:32.478843\n",
      "epoch : 210 -- time :  0:11:35.660679\n",
      "epoch : 211 -- time :  0:11:38.820935\n",
      "epoch : 212 -- time :  0:11:42.000538\n",
      "epoch : 213 -- time :  0:11:45.176156\n",
      "epoch : 214 -- time :  0:11:48.348221\n",
      "epoch : 215 -- time :  0:11:51.524313\n",
      "epoch : 216 -- time :  0:11:54.705226\n",
      "epoch : 217 -- time :  0:11:57.871562\n",
      "epoch : 218 -- time :  0:12:01.037785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 219 -- time :  0:12:04.217902\n",
      "epoch : 220 -- time :  0:12:07.419369\n",
      "epoch : 221 -- time :  0:12:10.608438\n",
      "epoch : 222 -- time :  0:12:13.784084\n",
      "epoch : 223 -- time :  0:12:17.235940\n",
      "epoch : 224 -- time :  0:12:20.441316\n",
      "epoch : 225 -- time :  0:12:23.624076\n",
      "epoch : 226 -- time :  0:12:26.857921\n",
      "epoch : 227 -- time :  0:12:30.078505\n",
      "epoch : 228 -- time :  0:12:33.270205\n",
      "epoch : 229 -- time :  0:12:36.444464\n",
      "epoch : 230 -- time :  0:12:39.637776\n",
      "epoch : 231 -- time :  0:12:42.852479\n",
      "epoch : 232 -- time :  0:12:46.034611\n",
      "epoch : 233 -- time :  0:12:49.268474\n",
      "epoch : 234 -- time :  0:12:53.088554\n",
      "epoch : 235 -- time :  0:12:56.271553\n",
      "epoch : 236 -- time :  0:12:59.445715\n",
      "epoch : 237 -- time :  0:13:02.633590\n",
      "epoch : 238 -- time :  0:13:05.834299\n",
      "epoch : 239 -- time :  0:13:09.045706\n",
      "epoch : 240 -- time :  0:13:12.261124\n",
      "epoch : 241 -- time :  0:13:15.493520\n",
      "epoch : 242 -- time :  0:13:18.681317\n",
      "epoch : 243 -- time :  0:13:21.888740\n",
      "epoch : 244 -- time :  0:13:25.092873\n",
      "epoch : 245 -- time :  0:13:28.304141\n",
      "epoch : 246 -- time :  0:13:31.515428\n",
      "epoch : 247 -- time :  0:13:34.700037\n",
      "epoch : 248 -- time :  0:13:37.874886\n",
      "epoch : 249 -- time :  0:13:41.062246\n",
      "epoch : 250 -- time :  0:13:44.259214\n",
      "epoch : 251 -- time :  0:13:47.476504\n",
      "epoch : 252 -- time :  0:13:50.657674\n",
      "epoch : 253 -- time :  0:13:53.888297\n",
      "epoch : 254 -- time :  0:13:57.100607\n",
      "epoch : 255 -- time :  0:14:00.309454\n",
      "epoch : 256 -- time :  0:14:03.532366\n",
      "epoch : 257 -- time :  0:14:06.726271\n",
      "epoch : 258 -- time :  0:14:09.914566\n",
      "epoch : 259 -- time :  0:14:13.124772\n",
      "epoch : 260 -- time :  0:14:16.332486\n",
      "epoch : 261 -- time :  0:14:19.550361\n",
      "epoch : 262 -- time :  0:14:22.766838\n",
      "epoch : 263 -- time :  0:14:25.970395\n",
      "epoch : 264 -- time :  0:14:29.154166\n",
      "epoch : 265 -- time :  0:14:32.343520\n",
      "epoch : 266 -- time :  0:14:35.539025\n",
      "epoch : 267 -- time :  0:14:38.749070\n",
      "epoch : 268 -- time :  0:14:41.950710\n",
      "epoch : 269 -- time :  0:14:45.156402\n",
      "epoch : 270 -- time :  0:14:48.349409\n",
      "epoch : 271 -- time :  0:14:51.553076\n",
      "epoch : 272 -- time :  0:14:54.766705\n",
      "epoch : 273 -- time :  0:14:58.033581\n",
      "epoch : 274 -- time :  0:15:01.246222\n",
      "epoch : 275 -- time :  0:15:04.450687\n",
      "epoch : 276 -- time :  0:15:07.694442\n",
      "epoch : 277 -- time :  0:15:10.873764\n",
      "epoch : 278 -- time :  0:15:14.060462\n",
      "epoch : 279 -- time :  0:15:17.262020\n",
      "epoch : 280 -- time :  0:15:20.472962\n",
      "epoch : 281 -- time :  0:15:23.702366\n",
      "epoch : 282 -- time :  0:15:26.914925\n",
      "epoch : 283 -- time :  0:15:30.136846\n",
      "epoch : 284 -- time :  0:15:33.316867\n",
      "epoch : 285 -- time :  0:15:36.496461\n",
      "epoch : 286 -- time :  0:15:39.708010\n",
      "epoch : 287 -- time :  0:15:42.905472\n",
      "epoch : 288 -- time :  0:15:46.104290\n",
      "epoch : 289 -- time :  0:15:49.285232\n",
      "epoch : 290 -- time :  0:15:52.463274\n",
      "epoch : 291 -- time :  0:15:55.663392\n",
      "epoch : 292 -- time :  0:15:58.848759\n",
      "epoch : 293 -- time :  0:16:02.027682\n",
      "epoch : 294 -- time :  0:16:05.207625\n",
      "epoch : 295 -- time :  0:16:08.392100\n",
      "epoch : 296 -- time :  0:16:11.618653\n",
      "epoch : 297 -- time :  0:16:14.804964\n",
      "epoch : 298 -- time :  0:16:18.016563\n",
      "epoch : 299 -- time :  0:16:21.197830\n",
      "epoch : 300 -- time :  0:16:24.397487\n",
      "epoch : 301 -- time :  0:16:27.585740\n",
      "epoch : 302 -- time :  0:16:30.793397\n",
      "epoch : 303 -- time :  0:16:34.004526\n",
      "epoch : 304 -- time :  0:16:37.191934\n",
      "epoch : 305 -- time :  0:16:40.372616\n",
      "epoch : 306 -- time :  0:16:43.567916\n",
      "epoch : 307 -- time :  0:16:46.776648\n",
      "epoch : 308 -- time :  0:16:49.997047\n",
      "epoch : 309 -- time :  0:16:53.198191\n",
      "epoch : 310 -- time :  0:16:56.390371\n",
      "epoch : 311 -- time :  0:16:59.584656\n",
      "epoch : 312 -- time :  0:17:02.757330\n",
      "epoch : 313 -- time :  0:17:05.955349\n",
      "epoch : 314 -- time :  0:17:09.142490\n",
      "epoch : 315 -- time :  0:17:12.336824\n",
      "epoch : 316 -- time :  0:17:15.530910\n",
      "epoch : 317 -- time :  0:17:18.709865\n",
      "epoch : 318 -- time :  0:17:21.953950\n",
      "epoch : 319 -- time :  0:17:25.159425\n",
      "epoch : 320 -- time :  0:17:28.337927\n",
      "epoch : 321 -- time :  0:17:31.522065\n",
      "epoch : 322 -- time :  0:17:34.736234\n",
      "epoch : 323 -- time :  0:17:37.990248\n",
      "epoch : 324 -- time :  0:17:41.172086\n",
      "epoch : 325 -- time :  0:17:44.360212\n",
      "epoch : 326 -- time :  0:17:47.561355\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_15/model_12/block1_conv2/Conv2D/Conv2DBackpropInput\n (defined at /anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_25818]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model_15/model_12/block1_conv2/Conv2D/Conv2DBackpropInput:\nIn[0] gradient_tape/model_15/model_12/block1_conv2/Conv2D/ShapeN:\t\nIn[1] model_15/model_12/block1_conv2/Conv2D/ReadVariableOp (defined at /anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/layers/convolutional.py:231)\t\nIn[2] gradient_tape/model_15/model_12/block1_conv2/ReluGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/base_events.py\", line 567, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/base_events.py\", line 1855, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2876, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2922, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3145, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-23-21ac72f3210c>\", line 25, in <module>\n>>>     train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs = 20001, batch_size = 16)\n>>> \n>>>   File \"<ipython-input-9-032021ca0777>\", line 43, in train\n>>>     g_loss = srgan.train_on_batch([lr_images, hr_images], [target_1, feature_map_hr_images])\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1900, in train_on_batch\n>>>     logs = self.train_function(iterator)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-21ac72f3210c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#Lancement de l'entrainement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerateur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminateur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-032021ca0777>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#Entrainement du SRGAN avec recuperation de l'erreur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map_hr_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#Suivi du temps d'apprentissage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                                     class_weight)\n\u001b[1;32m   1899\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_15/model_12/block1_conv2/Conv2D/Conv2DBackpropInput\n (defined at /anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_25818]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model_15/model_12/block1_conv2/Conv2D/Conv2DBackpropInput:\nIn[0] gradient_tape/model_15/model_12/block1_conv2/Conv2D/ShapeN:\t\nIn[1] model_15/model_12/block1_conv2/Conv2D/ReadVariableOp (defined at /anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/layers/convolutional.py:231)\t\nIn[2] gradient_tape/model_15/model_12/block1_conv2/ReluGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/base_events.py\", line 567, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/base_events.py\", line 1855, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2876, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2922, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3145, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-23-21ac72f3210c>\", line 25, in <module>\n>>>     train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs = 20001, batch_size = 16)\n>>> \n>>>   File \"<ipython-input-9-032021ca0777>\", line 43, in train\n>>>     g_loss = srgan.train_on_batch([lr_images, hr_images], [target_1, feature_map_hr_images])\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1900, in train_on_batch\n>>>     logs = self.train_function(iterator)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/anaconda/envs/azureml_py38_tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "lr_shape = (64, 64, 3)\n",
    "hr_shape = (256, 256, 3)\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "#Chargement du VGG et compilation avec la loss MSE\n",
    "#Ce reseau ne doit pas être entraine !\n",
    "vgg = creation_vgg(hr_shape)\n",
    "vgg.trainable = False\n",
    "vgg.compile(loss = 'mse',optimizer = optimizer,metrics = ['accuracy'])\n",
    "\n",
    "#Creation du discriminateur et compilation\n",
    "discriminateur = creation_discriminateur(hr_shape)\n",
    "discriminateur.compile(loss = 'mse',optimizer = optimizer,metrics=['accuracy'])\n",
    "\n",
    "#Creation du generateur\n",
    "generateur = creation_generateur(lr_shape)\n",
    "\n",
    "#Creation du SRGAN final\n",
    "srgan = creation_SRGAN(hr_shape,lr_shape)\n",
    "srgan.compile(loss=['binary_crossentropy','mse'], loss_weights = [1e-3,1], optimizer = optimizer)\n",
    "\n",
    "if (mode == \"train\"):\n",
    "    #Lancement de l'entrainement\n",
    "    train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs = 20001, batch_size = 16)\n",
    "elif (mode == \"inference\"):\n",
    "    #Prediction \n",
    "    prediction_et_resultat_plot(x_test_hr, x_test_lr, generateur, 2, 3, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae348b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Tensorflow",
   "language": "python",
   "name": "azureml_py38_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
