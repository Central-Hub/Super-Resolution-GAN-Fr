{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b261188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de chargement des images dans un dossier\n",
    "\"\"\"\n",
    "def load_dataset(path, image_shape):\n",
    "    \n",
    "    list_im = []\n",
    "    ims = []\n",
    "    \n",
    "    #On recupere la liste des fichiers contenu dans le dossier\n",
    "    for im in os.listdir(path):\n",
    "        list_im.append(os.path.join(path,im))\n",
    "    \n",
    "    #On charge les images, on les resize et on les transforme en numpy array\n",
    "    for i in list_im:\n",
    "        ims.append(np.array(Image.open(i).resize(image_shape)))\n",
    "    \n",
    "    #On retourne la liste d images de type numpy array\n",
    "    return np.array(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de normalisation des donnees : les pixels des images seront compris entre 0 et 1\n",
    "\"\"\"\n",
    "def normalisation(dataset):\n",
    "    return (dataset.astype(np.float32) - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86515bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de prediction de nouvelles images et affichage des résultats\n",
    "\"\"\"\n",
    "def prediction_et_resultat_plot(x_test_hr, x_test_lr, generateur, nb_images, it, mode):\n",
    "    \n",
    "    #On choisit aléatoirement nb_images parmi la base de test\n",
    "    indice_images = np.random.randint(0, x_test_hr.shape[0], nb_images)\n",
    "    lr_images = x_test_lr[indice_images]\n",
    "    hr_images = x_test_hr[indice_images]\n",
    "    \n",
    "    #Selon le mode, on charge les poids puis on prédit\n",
    "    if mode == \"train\":\n",
    "        images_generes = generator.predict(lr_images)\n",
    "    elif mode == \"inference\":\n",
    "        generateur.load_weights(\"./output2/gen_model_final.h5\")\n",
    "        images_generes = generateur.predict(lr_images)\n",
    "    \n",
    "    #Denormalisation des images\n",
    "    lr_images = 0.5 * lr_images + 0.5\n",
    "    hr_images = 0.5 * hr_images + 0.5\n",
    "    images_generes = 0.5 * images_generes + 0.5\n",
    "    \n",
    "    #Pour chaque, on cree un plot avec l image basse resolution / l image generee / l image haute resolution\n",
    "    for i in range(lr_images.shape[0]):\n",
    "        \n",
    "        plt.figure(figsize=(20, 40))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(lr_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image basse résolution\")\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(images_generes[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image générée\")\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(hr_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"image haute résolution\")\n",
    "        \n",
    "        plt.savefig('./output2/result_image_%d.png' % i)\n",
    "        plt.close()  \n",
    "\n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de chargement du modele VGG19\n",
    "\"\"\"\n",
    "def creation_vgg(hr_shape):\n",
    "    vgg = VGG19(include_top = False ,  input_shape = hr_shape , weights=\"imagenet\")\n",
    "    features = vgg.get_layer(index = 9).output\n",
    "    model = Model(inputs=[vgg.inputs], outputs=[features])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du discriminateur (architecture provenant de l'article de recherche du SRGAN(voir readme))\n",
    "\"\"\"\n",
    "def creation_discriminateur(hr_shape):\n",
    "\n",
    "    def discri_block(inp, filters, strides = 1, bn = True):\n",
    "        db = Conv2D(filters = filters, kernel_size = 3, strides = strides, padding='same')(inp)\n",
    "        if bn:\n",
    "            db = BatchNormalization(momentum = 0.8)(db)\n",
    "        db = LeakyReLU(alpha = 0.2)(db)\n",
    "        return db\n",
    "\n",
    "    inp = Input(shape = hr_shape)\n",
    "\n",
    "    d = discri_block(inp, 64, 1, bn=False)\n",
    "    d = discri_block(d, 64, 2, True)\n",
    "    d = discri_block(d, 128, 1, True)\n",
    "    d = discri_block(d, 128, 2, True)\n",
    "    d = discri_block(d, 256, 1, True)\n",
    "    d = discri_block(d, 256, 2, True)\n",
    "    d = discri_block(d, 512, 1, True)\n",
    "    d = discri_block(d, 512, 2, True)\n",
    "\n",
    "    d = Dense(1024)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    d_final = Dense(1, activation = 'sigmoid')(d)\n",
    "\n",
    "    return Model(inp, d_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du generateur (architecture provenant de l'article de recherche du SRGAN(voir readme))\n",
    "\"\"\"\n",
    "def creation_generateur(lr_shape):\n",
    "    \n",
    "    def residual_block(inp):\n",
    "    \n",
    "        model_rb = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(inp)\n",
    "        model_rb = BatchNormalization(momentum = 0.8)(model_rb)\n",
    "        model_rb = PReLU(alpha_initializer='zeros')(model_rb)\n",
    "        model_rb = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model_rb)\n",
    "        model_rb = BatchNormalization(momentum = 0.8)(model_rb)\n",
    "        model_rb = add([inp, model_rb])\n",
    "    \n",
    "        return model_rb\n",
    "\n",
    "    def deconvolution(inp):\n",
    "    \n",
    "        model_dc = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = \"same\")(inp)\n",
    "        model_dc = UpSampling2D(size = 2)(model_dc)\n",
    "        model_dc = LeakyReLU(alpha = 0.2)(model_dc)\n",
    "    \n",
    "        return model_dc\n",
    "\n",
    "    inp = Input(shape = lr_shape)\n",
    "\n",
    "    model_g = Conv2D(filters = 64, kernel_size=9, strides=1, padding='same')(inp)\n",
    "    model_g = PReLU(alpha_initializer='zeros')(model_g)\n",
    "    \n",
    "    sauv_out = model_g\n",
    "\n",
    "    for i in range(16):\n",
    "        model_g = residual_block(model_g)\n",
    "\n",
    "    model_g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='same')(model_g)\n",
    "    model_g = BatchNormalization(momentum=0.8)(model_g)\n",
    "    model_g = add([sauv_out, model_g])\n",
    "\n",
    "    for i in range(2):\n",
    "        model_g = deconvolution(model_g)\n",
    "\n",
    "    model_g = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = 'same', activation = 'tanh')(model_g)\n",
    "\n",
    "    return Model(inp, model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3767bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction de creation du SRGAN\n",
    "\"\"\"\n",
    "def creation_SRGAN(hr_shape, lr_shape):\n",
    "    \n",
    "    lr_images = Input(lr_shape)\n",
    "    hr_images = Input(hr_shape)\n",
    "    \n",
    "    generated_hr = generateur(lr_images)\n",
    "    generated_feature_map = vgg(generated_hr)\n",
    "    \n",
    "    #On entraine pas le discriminateur ici (on le fait avant)\n",
    "    discriminateur.trainable = False\n",
    "    \n",
    "    return Model([lr_images, hr_images], [discriminateur(generated_hr), generated_feature_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction d entrainement du modele\n",
    "\"\"\"\n",
    "def train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs, batch_size):\n",
    "        \n",
    "        shape_output_discrinateur = (16, 16, 1)\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(epochs + 1):\n",
    "\n",
    "            #On choisit aléatoirement nb_images parmi la base d entrainement\n",
    "            indice_images = np.random.randint(0, x_test_hr.shape[0], batch_size)\n",
    "            lr_images = x_test_lr[indice_images]\n",
    "            hr_images = x_test_hr[indice_images]\n",
    "\n",
    "            generated_images = generateur.predict(lr_images)\n",
    "            \n",
    "            #L output shape du discriminateur est : (batch_size,16,16,1)\n",
    "            #on associe la classe 1 aux vrais images et 0 aux images generees\n",
    "            target_1 = np.ones((batch_size,) + shape_output_discrinateur)\n",
    "            target_0 = np.zeros((batch_size,) + shape_output_discrinateur)\n",
    "            \n",
    "            #Entrainement du discriminateur et recuperation des erreurs\n",
    "            d_loss_vrai_im = discriminateur.train_on_batch(hr_images, target_1)\n",
    "            d_loss_gen_im = discriminateur.train_on_batch(generated_images, target_0)\n",
    "            \n",
    "            #Moyenne des erreurs\n",
    "            #d_loss = 0.5 * np.add(d_loss_vrai_im, d_loss_gen_im)\n",
    "\n",
    "            #On choisit aléatoirement nb_images parmi la base d entrainement\n",
    "            indice_images = np.random.randint(0, x_test_hr.shape[0], batch_size)\n",
    "            lr_images = x_test_lr[indice_images]\n",
    "            hr_images = x_test_hr[indice_images]\n",
    "\n",
    "            target_1 = np.ones((batch_size,) + shape_output_discrinateur)\n",
    "            \n",
    "            #On récupères les features maps des images huates résolutions (du modèle VGG19) \n",
    "            #pour les comparer aux features maps des images generees\n",
    "            \n",
    "            feature_map_hr_images = vgg.predict(hr_images)\n",
    "            \n",
    "            #Entrainement du SRGAN avec recuperation de l'erreur\n",
    "            g_loss = srgan.train_on_batch([lr_images, hr_images], [target_1, feature_map_hr_images])\n",
    "\n",
    "            #Suivi du temps d'apprentissage\n",
    "            time = datetime.datetime.now() - start_time\n",
    "            #Affichage des epochs et du temps\n",
    "            print(\"epoch : %d -- time :  %s\" % (epoch, time))\n",
    "                     \n",
    "            #Affichage des erreurs\n",
    "            #print(\"Loss HR , Loss LR, Loss GAN\")\n",
    "            #print(d_loss, g_loss)\n",
    "            \n",
    "            #Affichage des images generees et sauvegarde des poids des neurones des differents reseaux toutes les 1k images\n",
    "            if (epoch % 1000 == 0) and (epoch > 0):\n",
    "                prediction_et_resultat_plot(x_test_hr, x_test_lr, generator, 2, epoch, \"train\")\n",
    "                generateur.save_weights('./output2/gen_model_%d.h5' % epoch)\n",
    "                #discriminator.save_weights('./output2/dis_model_%d.h5' % epoch)\n",
    "                #combined.save_weights('./output2/srgan_model_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image haute resolution (hr) de taille 256*256\n",
    "#image basse resolution (lr) de taille 64*64\n",
    "#Facteur de 4 entre les images haute et basse résolution\n",
    "image_shape1 = (256,256)\n",
    "image_shape2 = (64,64)\n",
    "\n",
    "#Chargement / Resize / Normalisation des donnees\n",
    "x_train_hr = normalisation(load_dataset(\"./div2k/DIV2K_train_HR\", image_shape1))\n",
    "x_train_lr = normalisation(load_dataset(\"./div2k/DIV2K_train_LR_bicubic/X2\", image_shape2))\n",
    "x_test_hr = normalisation(load_dataset(\"./div2k/DIV2K_valid_HR\", image_shape1))\n",
    "x_test_lr = normalisation(load_dataset(\"./div2k/DIV2K_valid_LR_bicubic/X2\", image_shape2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\"\n",
    "#mode = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d77d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_shape = (64, 64, 3)\n",
    "hr_shape = (256, 256, 3)\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "#Chargement du VGG et compilation avec la loss MSE\n",
    "#Ce reseau ne doit pas être entraine !\n",
    "vgg = creation_vgg(hr_shape)\n",
    "vgg.trainable = False\n",
    "vgg.compile(loss = 'mse',optimizer = optimizer,metrics = ['accuracy'])\n",
    "\n",
    "#Creation du discriminateur et compilation\n",
    "discriminateur = creation_discriminateur(hr_shape)\n",
    "discriminateur.compile(loss = 'mse',optimizer = optimizer,metrics=['accuracy'])\n",
    "\n",
    "#Creation du generateur\n",
    "generateur = creation_generateur(lr_shape)\n",
    "\n",
    "#Creation du SRGAN final\n",
    "srgan = creation_SRGAN(hr_shape,lr_shape)\n",
    "srgan.compile(loss=['binary_crossentropy','mse'], loss_weights = [1e-3,1], optimizer = optimizer)\n",
    "\n",
    "if (mode == \"train\"):\n",
    "    #Lancement de l'entrainement\n",
    "    train(generateur, discriminateur, srgan, vgg, x_train_hr, x_train_lr, epochs = 20001, batch_size = 16)\n",
    "elif (mode == \"inference\"):\n",
    "    #Prediction \n",
    "    prediction_et_resultat_plot(x_test_hr, x_test_lr, generateur, 2, 3, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae348b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Tensorflow",
   "language": "python",
   "name": "azureml_py38_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
